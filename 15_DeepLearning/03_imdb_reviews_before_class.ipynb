{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_imdb_reviews_before_class.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "IA2RtMRjncZS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Working with text\n",
        "\n",
        "In this problem, we will load movie reviews from IMDB, a famous movie database and website, and we will try to predict whether the review is positive or negative."
      ]
    },
    {
      "metadata": {
        "id": "n58IW5HrncZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, the function we will use to diagnose the performance of our model"
      ]
    },
    {
      "metadata": {
        "id": "9EFkn2QsncZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88e4710b-8a3a-4257-b366-9f59456ceead"
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "plt.style.use('seaborn-talk')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J6oDgVZGncZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_metric(history, metric):\n",
        "    history_dict = history.history\n",
        "    values = history_dict[metric]\n",
        "    if 'val_' + metric in history_dict.keys():  \n",
        "        val_values = history_dict['val_' + metric]\n",
        "\n",
        "    epochs = range(1, len(values) + 1)\n",
        "\n",
        "    if 'val_' + metric in history_dict.keys():  \n",
        "        plt.plot(epochs, val_values, label='Validation')\n",
        "    plt.semilogy(epochs, values, label='Training')\n",
        "\n",
        "    if 'val_' + metric in history_dict.keys():  \n",
        "        plt.title('Training and validation %s' % metric)\n",
        "    else:\n",
        "        plt.title('Training %s' % metric)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VBRYBZGncZ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Input data"
      ]
    },
    {
      "metadata": {
        "id": "rP0TaspyncaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "890ab179-c843-4fe4-ebeb-850df0945842"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5QreVkXncaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ee310274-176e-415e-b7c0-1cfb4681fa12"
      },
      "cell_type": "code",
      "source": [
        "# Run this to download the data prior to the lecture\n",
        "train, test = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hqMsjJk7ncaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4b4a998-92f4-45e9-9801-809b6f752a3c"
      },
      "cell_type": "code",
      "source": [
        "train[0].shape, train[1].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), (25000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "GhldU2jmocwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "370fb420-ca09-48d4-a13b-9dabaf88556c"
      },
      "cell_type": "code",
      "source": [
        "# Positive Review or Negative Review\n",
        "train[1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "SvaDf_ONncaa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Why are these *texts* numbers?"
      ]
    },
    {
      "metadata": {
        "id": "d4NKUEq4ncag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = train[0]\n",
        "y_train = train[1]\n",
        "x_test = test[0]\n",
        "y_test = test[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C2poMEUnncam",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These are actually indices in a word index"
      ]
    },
    {
      "metadata": {
        "id": "eBadmCKGncar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "163ea941-69b7-4e2e-c0fb-16b7f1282568"
      },
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SNxtzOEbnca_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17401
        },
        "outputId": "be02e97c-3b40-4d85-b3bf-abf8548894fc"
      },
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34701,\n",
              " 'tsukino': 52006,\n",
              " 'nunnery': 52007,\n",
              " 'sonja': 16816,\n",
              " 'vani': 63951,\n",
              " 'woods': 1408,\n",
              " 'spiders': 16115,\n",
              " 'hanging': 2345,\n",
              " 'woody': 2289,\n",
              " 'trawling': 52008,\n",
              " \"hold's\": 52009,\n",
              " 'comically': 11307,\n",
              " 'localized': 40830,\n",
              " 'disobeying': 30568,\n",
              " \"'royale\": 52010,\n",
              " \"harpo's\": 40831,\n",
              " 'canet': 52011,\n",
              " 'aileen': 19313,\n",
              " 'acurately': 52012,\n",
              " \"diplomat's\": 52013,\n",
              " 'rickman': 25242,\n",
              " 'arranged': 6746,\n",
              " 'rumbustious': 52014,\n",
              " 'familiarness': 52015,\n",
              " \"spider'\": 52016,\n",
              " 'hahahah': 68804,\n",
              " \"wood'\": 52017,\n",
              " 'transvestism': 40833,\n",
              " \"hangin'\": 34702,\n",
              " 'bringing': 2338,\n",
              " 'seamier': 40834,\n",
              " 'wooded': 34703,\n",
              " 'bravora': 52018,\n",
              " 'grueling': 16817,\n",
              " 'wooden': 1636,\n",
              " 'wednesday': 16818,\n",
              " \"'prix\": 52019,\n",
              " 'altagracia': 34704,\n",
              " 'circuitry': 52020,\n",
              " 'crotch': 11585,\n",
              " 'busybody': 57766,\n",
              " \"tart'n'tangy\": 52021,\n",
              " 'burgade': 14129,\n",
              " 'thrace': 52023,\n",
              " \"tom's\": 11038,\n",
              " 'snuggles': 52025,\n",
              " 'francesco': 29114,\n",
              " 'complainers': 52027,\n",
              " 'templarios': 52125,\n",
              " '272': 40835,\n",
              " '273': 52028,\n",
              " 'zaniacs': 52130,\n",
              " '275': 34706,\n",
              " 'consenting': 27631,\n",
              " 'snuggled': 40836,\n",
              " 'inanimate': 15492,\n",
              " 'uality': 52030,\n",
              " 'bronte': 11926,\n",
              " 'errors': 4010,\n",
              " 'dialogs': 3230,\n",
              " \"yomada's\": 52031,\n",
              " \"madman's\": 34707,\n",
              " 'dialoge': 30585,\n",
              " 'usenet': 52033,\n",
              " 'videodrome': 40837,\n",
              " \"kid'\": 26338,\n",
              " 'pawed': 52034,\n",
              " \"'girlfriend'\": 30569,\n",
              " \"'pleasure\": 52035,\n",
              " \"'reloaded'\": 52036,\n",
              " \"kazakos'\": 40839,\n",
              " 'rocque': 52037,\n",
              " 'mailings': 52038,\n",
              " 'brainwashed': 11927,\n",
              " 'mcanally': 16819,\n",
              " \"tom''\": 52039,\n",
              " 'kurupt': 25243,\n",
              " 'affiliated': 21905,\n",
              " 'babaganoosh': 52040,\n",
              " \"noe's\": 40840,\n",
              " 'quart': 40841,\n",
              " 'kids': 359,\n",
              " 'uplifting': 5034,\n",
              " 'controversy': 7093,\n",
              " 'kida': 21906,\n",
              " 'kidd': 23379,\n",
              " \"error'\": 52041,\n",
              " 'neurologist': 52042,\n",
              " 'spotty': 18510,\n",
              " 'cobblers': 30570,\n",
              " 'projection': 9878,\n",
              " 'fastforwarding': 40842,\n",
              " 'sters': 52043,\n",
              " \"eggar's\": 52044,\n",
              " 'etherything': 52045,\n",
              " 'gateshead': 40843,\n",
              " 'airball': 34708,\n",
              " 'unsinkable': 25244,\n",
              " 'stern': 7180,\n",
              " \"cervi's\": 52046,\n",
              " 'dnd': 40844,\n",
              " 'dna': 11586,\n",
              " 'insecurity': 20598,\n",
              " \"'reboot'\": 52047,\n",
              " 'trelkovsky': 11037,\n",
              " 'jaekel': 52048,\n",
              " 'sidebars': 52049,\n",
              " \"sforza's\": 52050,\n",
              " 'distortions': 17633,\n",
              " 'mutinies': 52051,\n",
              " 'sermons': 30602,\n",
              " '7ft': 40846,\n",
              " 'boobage': 52052,\n",
              " \"o'bannon's\": 52053,\n",
              " 'populations': 23380,\n",
              " 'chulak': 52054,\n",
              " 'mesmerize': 27633,\n",
              " 'quinnell': 52055,\n",
              " 'yahoo': 10307,\n",
              " 'meteorologist': 52057,\n",
              " 'beswick': 42577,\n",
              " 'boorman': 15493,\n",
              " 'voicework': 40847,\n",
              " \"ster'\": 52058,\n",
              " 'blustering': 22922,\n",
              " 'hj': 52059,\n",
              " 'intake': 27634,\n",
              " 'morally': 5621,\n",
              " 'jumbling': 40849,\n",
              " 'bowersock': 52060,\n",
              " \"'porky's'\": 52061,\n",
              " 'gershon': 16821,\n",
              " 'ludicrosity': 40850,\n",
              " 'coprophilia': 52062,\n",
              " 'expressively': 40851,\n",
              " \"india's\": 19500,\n",
              " \"post's\": 34710,\n",
              " 'wana': 52063,\n",
              " 'wang': 5283,\n",
              " 'wand': 30571,\n",
              " 'wane': 25245,\n",
              " 'edgeways': 52321,\n",
              " 'titanium': 34711,\n",
              " 'pinta': 40852,\n",
              " 'want': 178,\n",
              " 'pinto': 30572,\n",
              " 'whoopdedoodles': 52065,\n",
              " 'tchaikovsky': 21908,\n",
              " 'travel': 2103,\n",
              " \"'victory'\": 52066,\n",
              " 'copious': 11928,\n",
              " 'gouge': 22433,\n",
              " \"chapters'\": 52067,\n",
              " 'barbra': 6702,\n",
              " 'uselessness': 30573,\n",
              " \"wan'\": 52068,\n",
              " 'assimilated': 27635,\n",
              " 'petiot': 16116,\n",
              " 'most\\x85and': 52069,\n",
              " 'dinosaurs': 3930,\n",
              " 'wrong': 352,\n",
              " 'seda': 52070,\n",
              " 'stollen': 52071,\n",
              " 'sentencing': 34712,\n",
              " 'ouroboros': 40853,\n",
              " 'assimilates': 40854,\n",
              " 'colorfully': 40855,\n",
              " 'glenne': 27636,\n",
              " 'dongen': 52072,\n",
              " 'subplots': 4760,\n",
              " 'kiloton': 52073,\n",
              " 'chandon': 23381,\n",
              " \"effect'\": 34713,\n",
              " 'snugly': 27637,\n",
              " 'kuei': 40856,\n",
              " 'welcomed': 9092,\n",
              " 'dishonor': 30071,\n",
              " 'concurrence': 52075,\n",
              " 'stoicism': 23382,\n",
              " \"guys'\": 14896,\n",
              " \"beroemd'\": 52077,\n",
              " 'butcher': 6703,\n",
              " \"melfi's\": 40857,\n",
              " 'aargh': 30623,\n",
              " 'playhouse': 20599,\n",
              " 'wickedly': 11308,\n",
              " 'fit': 1180,\n",
              " 'labratory': 52078,\n",
              " 'lifeline': 40859,\n",
              " 'screaming': 1927,\n",
              " 'fix': 4287,\n",
              " 'cineliterate': 52079,\n",
              " 'fic': 52080,\n",
              " 'fia': 52081,\n",
              " 'fig': 34714,\n",
              " 'fmvs': 52082,\n",
              " 'fie': 52083,\n",
              " 'reentered': 52084,\n",
              " 'fin': 30574,\n",
              " 'doctresses': 52085,\n",
              " 'fil': 52086,\n",
              " 'zucker': 12606,\n",
              " 'ached': 31931,\n",
              " 'counsil': 52088,\n",
              " 'paterfamilias': 52089,\n",
              " 'songwriter': 13885,\n",
              " 'shivam': 34715,\n",
              " 'hurting': 9654,\n",
              " 'effects': 299,\n",
              " 'slauther': 52090,\n",
              " \"'flame'\": 52091,\n",
              " 'sommerset': 52092,\n",
              " 'interwhined': 52093,\n",
              " 'whacking': 27638,\n",
              " 'bartok': 52094,\n",
              " 'barton': 8775,\n",
              " 'frewer': 21909,\n",
              " \"fi'\": 52095,\n",
              " 'ingrid': 6192,\n",
              " 'stribor': 30575,\n",
              " 'approporiately': 52096,\n",
              " 'wobblyhand': 52097,\n",
              " 'tantalisingly': 52098,\n",
              " 'ankylosaurus': 52099,\n",
              " 'parasites': 17634,\n",
              " 'childen': 52100,\n",
              " \"jenkins'\": 52101,\n",
              " 'metafiction': 52102,\n",
              " 'golem': 17635,\n",
              " 'indiscretion': 40860,\n",
              " \"reeves'\": 23383,\n",
              " \"inamorata's\": 57781,\n",
              " 'brittannica': 52104,\n",
              " 'adapt': 7916,\n",
              " \"russo's\": 30576,\n",
              " 'guitarists': 48246,\n",
              " 'abbott': 10553,\n",
              " 'abbots': 40861,\n",
              " 'lanisha': 17649,\n",
              " 'magickal': 40863,\n",
              " 'mattter': 52105,\n",
              " \"'willy\": 52106,\n",
              " 'pumpkins': 34716,\n",
              " 'stuntpeople': 52107,\n",
              " 'estimate': 30577,\n",
              " 'ugghhh': 40864,\n",
              " 'gameplay': 11309,\n",
              " \"wern't\": 52108,\n",
              " \"n'sync\": 40865,\n",
              " 'sickeningly': 16117,\n",
              " 'chiara': 40866,\n",
              " 'disturbed': 4011,\n",
              " 'portmanteau': 40867,\n",
              " 'ineffectively': 52109,\n",
              " \"duchonvey's\": 82143,\n",
              " \"nasty'\": 37519,\n",
              " 'purpose': 1285,\n",
              " 'lazers': 52112,\n",
              " 'lightened': 28105,\n",
              " 'kaliganj': 52113,\n",
              " 'popularism': 52114,\n",
              " \"damme's\": 18511,\n",
              " 'stylistics': 30578,\n",
              " 'mindgaming': 52115,\n",
              " 'spoilerish': 46449,\n",
              " \"'corny'\": 52117,\n",
              " 'boerner': 34718,\n",
              " 'olds': 6792,\n",
              " 'bakelite': 52118,\n",
              " 'renovated': 27639,\n",
              " 'forrester': 27640,\n",
              " \"lumiere's\": 52119,\n",
              " 'gaskets': 52024,\n",
              " 'needed': 884,\n",
              " 'smight': 34719,\n",
              " 'master': 1297,\n",
              " \"edie's\": 25905,\n",
              " 'seeber': 40868,\n",
              " 'hiya': 52120,\n",
              " 'fuzziness': 52121,\n",
              " 'genesis': 14897,\n",
              " 'rewards': 12607,\n",
              " 'enthrall': 30579,\n",
              " \"'about\": 40869,\n",
              " \"recollection's\": 52122,\n",
              " 'mutilated': 11039,\n",
              " 'fatherlands': 52123,\n",
              " \"fischer's\": 52124,\n",
              " 'positively': 5399,\n",
              " '270': 34705,\n",
              " 'ahmed': 34720,\n",
              " 'zatoichi': 9836,\n",
              " 'bannister': 13886,\n",
              " 'anniversaries': 52127,\n",
              " \"helm's\": 30580,\n",
              " \"'work'\": 52128,\n",
              " 'exclaimed': 34721,\n",
              " \"'unfunny'\": 52129,\n",
              " '274': 52029,\n",
              " 'feeling': 544,\n",
              " \"wanda's\": 52131,\n",
              " 'dolan': 33266,\n",
              " '278': 52133,\n",
              " 'peacoat': 52134,\n",
              " 'brawny': 40870,\n",
              " 'mishra': 40871,\n",
              " 'worlders': 40872,\n",
              " 'protags': 52135,\n",
              " 'skullcap': 52136,\n",
              " 'dastagir': 57596,\n",
              " 'affairs': 5622,\n",
              " 'wholesome': 7799,\n",
              " 'hymen': 52137,\n",
              " 'paramedics': 25246,\n",
              " 'unpersons': 52138,\n",
              " 'heavyarms': 52139,\n",
              " 'affaire': 52140,\n",
              " 'coulisses': 52141,\n",
              " 'hymer': 40873,\n",
              " 'kremlin': 52142,\n",
              " 'shipments': 30581,\n",
              " 'pixilated': 52143,\n",
              " \"'00s\": 30582,\n",
              " 'diminishing': 18512,\n",
              " 'cinematic': 1357,\n",
              " 'resonates': 14898,\n",
              " 'simplify': 40874,\n",
              " \"nature'\": 40875,\n",
              " 'temptresses': 40876,\n",
              " 'reverence': 16822,\n",
              " 'resonated': 19502,\n",
              " 'dailey': 34722,\n",
              " '2\\x85': 52144,\n",
              " 'treize': 27641,\n",
              " 'majo': 52145,\n",
              " 'kiya': 21910,\n",
              " 'woolnough': 52146,\n",
              " 'thanatos': 39797,\n",
              " 'sandoval': 35731,\n",
              " 'dorama': 40879,\n",
              " \"o'shaughnessy\": 52147,\n",
              " 'tech': 4988,\n",
              " 'fugitives': 32018,\n",
              " 'teck': 30583,\n",
              " \"'e'\": 76125,\n",
              " 'doesn’t': 40881,\n",
              " 'purged': 52149,\n",
              " 'saying': 657,\n",
              " \"martians'\": 41095,\n",
              " 'norliss': 23418,\n",
              " 'dickey': 27642,\n",
              " 'dicker': 52152,\n",
              " \"'sependipity\": 52153,\n",
              " 'padded': 8422,\n",
              " 'ordell': 57792,\n",
              " \"sturges'\": 40882,\n",
              " 'independentcritics': 52154,\n",
              " 'tempted': 5745,\n",
              " \"atkinson's\": 34724,\n",
              " 'hounded': 25247,\n",
              " 'apace': 52155,\n",
              " 'clicked': 15494,\n",
              " \"'humor'\": 30584,\n",
              " \"martino's\": 17177,\n",
              " \"'supporting\": 52156,\n",
              " 'warmongering': 52032,\n",
              " \"zemeckis's\": 34725,\n",
              " 'lube': 21911,\n",
              " 'shocky': 52157,\n",
              " 'plate': 7476,\n",
              " 'plata': 40883,\n",
              " 'sturgess': 40884,\n",
              " \"nerds'\": 40885,\n",
              " 'plato': 20600,\n",
              " 'plath': 34726,\n",
              " 'platt': 40886,\n",
              " 'mcnab': 52159,\n",
              " 'clumsiness': 27643,\n",
              " 'altogether': 3899,\n",
              " 'massacring': 42584,\n",
              " 'bicenntinial': 52160,\n",
              " 'skaal': 40887,\n",
              " 'droning': 14360,\n",
              " 'lds': 8776,\n",
              " 'jaguar': 21912,\n",
              " \"cale's\": 34727,\n",
              " 'nicely': 1777,\n",
              " 'mummy': 4588,\n",
              " \"lot's\": 18513,\n",
              " 'patch': 10086,\n",
              " 'kerkhof': 50202,\n",
              " \"leader's\": 52161,\n",
              " \"'movie\": 27644,\n",
              " 'uncomfirmed': 52162,\n",
              " 'heirloom': 40888,\n",
              " 'wrangle': 47360,\n",
              " 'emotion\\x85': 52163,\n",
              " \"'stargate'\": 52164,\n",
              " 'pinoy': 40889,\n",
              " 'conchatta': 40890,\n",
              " 'broeke': 41128,\n",
              " 'advisedly': 40891,\n",
              " \"barker's\": 17636,\n",
              " 'descours': 52166,\n",
              " 'lots': 772,\n",
              " 'lotr': 9259,\n",
              " 'irs': 9879,\n",
              " 'lott': 52167,\n",
              " 'xvi': 40892,\n",
              " 'irk': 34728,\n",
              " 'irl': 52168,\n",
              " 'ira': 6887,\n",
              " 'belzer': 21913,\n",
              " 'irc': 52169,\n",
              " 'ire': 27645,\n",
              " 'requisites': 40893,\n",
              " 'discipline': 7693,\n",
              " 'lyoko': 52961,\n",
              " 'extend': 11310,\n",
              " 'nature': 873,\n",
              " \"'dickie'\": 52170,\n",
              " 'optimist': 40894,\n",
              " 'lapping': 30586,\n",
              " 'superficial': 3900,\n",
              " 'vestment': 52171,\n",
              " 'extent': 2823,\n",
              " 'tendons': 52172,\n",
              " \"heller's\": 52173,\n",
              " 'quagmires': 52174,\n",
              " 'miyako': 52175,\n",
              " 'moocow': 20601,\n",
              " \"coles'\": 52176,\n",
              " 'lookit': 40895,\n",
              " 'ravenously': 52177,\n",
              " 'levitating': 40896,\n",
              " 'perfunctorily': 52178,\n",
              " 'lookin': 30587,\n",
              " \"lot'\": 40898,\n",
              " 'lookie': 52179,\n",
              " 'fearlessly': 34870,\n",
              " 'libyan': 52181,\n",
              " 'fondles': 40899,\n",
              " 'gopher': 35714,\n",
              " 'wearying': 40901,\n",
              " \"nz's\": 52182,\n",
              " 'minuses': 27646,\n",
              " 'puposelessly': 52183,\n",
              " 'shandling': 52184,\n",
              " 'decapitates': 31268,\n",
              " 'humming': 11929,\n",
              " \"'nother\": 40902,\n",
              " 'smackdown': 21914,\n",
              " 'underdone': 30588,\n",
              " 'frf': 40903,\n",
              " 'triviality': 52185,\n",
              " 'fro': 25248,\n",
              " 'bothers': 8777,\n",
              " \"'kensington\": 52186,\n",
              " 'much': 73,\n",
              " 'muco': 34730,\n",
              " 'wiseguy': 22615,\n",
              " \"richie's\": 27648,\n",
              " 'tonino': 40904,\n",
              " 'unleavened': 52187,\n",
              " 'fry': 11587,\n",
              " \"'tv'\": 40905,\n",
              " 'toning': 40906,\n",
              " 'obese': 14361,\n",
              " 'sensationalized': 30589,\n",
              " 'spiv': 40907,\n",
              " 'spit': 6259,\n",
              " 'arkin': 7364,\n",
              " 'charleton': 21915,\n",
              " 'jeon': 16823,\n",
              " 'boardroom': 21916,\n",
              " 'doubts': 4989,\n",
              " 'spin': 3084,\n",
              " 'hepo': 53083,\n",
              " 'wildcat': 27649,\n",
              " 'venoms': 10584,\n",
              " 'misconstrues': 52191,\n",
              " 'mesmerising': 18514,\n",
              " 'misconstrued': 40908,\n",
              " 'rescinds': 52192,\n",
              " 'prostrate': 52193,\n",
              " 'majid': 40909,\n",
              " 'climbed': 16479,\n",
              " 'canoeing': 34731,\n",
              " 'majin': 52195,\n",
              " 'animie': 57804,\n",
              " 'sylke': 40910,\n",
              " 'conditioned': 14899,\n",
              " 'waddell': 40911,\n",
              " '3\\x85': 52196,\n",
              " 'hyperdrive': 41188,\n",
              " 'conditioner': 34732,\n",
              " 'bricklayer': 53153,\n",
              " 'hong': 2576,\n",
              " 'memoriam': 52198,\n",
              " 'inventively': 30592,\n",
              " \"levant's\": 25249,\n",
              " 'portobello': 20638,\n",
              " 'remand': 52200,\n",
              " 'mummified': 19504,\n",
              " 'honk': 27650,\n",
              " 'spews': 19505,\n",
              " 'visitations': 40912,\n",
              " 'mummifies': 52201,\n",
              " 'cavanaugh': 25250,\n",
              " 'zeon': 23385,\n",
              " \"jungle's\": 40913,\n",
              " 'viertel': 34733,\n",
              " 'frenchmen': 27651,\n",
              " 'torpedoes': 52202,\n",
              " 'schlessinger': 52203,\n",
              " 'torpedoed': 34734,\n",
              " 'blister': 69876,\n",
              " 'cinefest': 52204,\n",
              " 'furlough': 34735,\n",
              " 'mainsequence': 52205,\n",
              " 'mentors': 40914,\n",
              " 'academic': 9094,\n",
              " 'stillness': 20602,\n",
              " 'academia': 40915,\n",
              " 'lonelier': 52206,\n",
              " 'nibby': 52207,\n",
              " \"losers'\": 52208,\n",
              " 'cineastes': 40916,\n",
              " 'corporate': 4449,\n",
              " 'massaging': 40917,\n",
              " 'bellow': 30593,\n",
              " 'absurdities': 19506,\n",
              " 'expetations': 53241,\n",
              " 'nyfiken': 40918,\n",
              " 'mehras': 75638,\n",
              " 'lasse': 52209,\n",
              " 'visability': 52210,\n",
              " 'militarily': 33946,\n",
              " \"elder'\": 52211,\n",
              " 'gainsbourg': 19023,\n",
              " 'hah': 20603,\n",
              " 'hai': 13420,\n",
              " 'haj': 34736,\n",
              " 'hak': 25251,\n",
              " 'hal': 4311,\n",
              " 'ham': 4892,\n",
              " 'duffer': 53259,\n",
              " 'haa': 52213,\n",
              " 'had': 66,\n",
              " 'advancement': 11930,\n",
              " 'hag': 16825,\n",
              " \"hand'\": 25252,\n",
              " 'hay': 13421,\n",
              " 'mcnamara': 20604,\n",
              " \"mozart's\": 52214,\n",
              " 'duffel': 30731,\n",
              " 'haq': 30594,\n",
              " 'har': 13887,\n",
              " 'has': 44,\n",
              " 'hat': 2401,\n",
              " 'hav': 40919,\n",
              " 'haw': 30595,\n",
              " 'figtings': 52215,\n",
              " 'elders': 15495,\n",
              " 'underpanted': 52216,\n",
              " 'pninson': 52217,\n",
              " 'unequivocally': 27652,\n",
              " \"barbara's\": 23673,\n",
              " \"bello'\": 52219,\n",
              " 'indicative': 12997,\n",
              " 'yawnfest': 40920,\n",
              " 'hexploitation': 52220,\n",
              " \"loder's\": 52221,\n",
              " 'sleuthing': 27653,\n",
              " \"justin's\": 32622,\n",
              " \"'ball\": 52222,\n",
              " \"'summer\": 52223,\n",
              " \"'demons'\": 34935,\n",
              " \"mormon's\": 52225,\n",
              " \"laughton's\": 34737,\n",
              " 'debell': 52226,\n",
              " 'shipyard': 39724,\n",
              " 'unabashedly': 30597,\n",
              " 'disks': 40401,\n",
              " 'crowd': 2290,\n",
              " 'crowe': 10087,\n",
              " \"vancouver's\": 56434,\n",
              " 'mosques': 34738,\n",
              " 'crown': 6627,\n",
              " 'culpas': 52227,\n",
              " 'crows': 27654,\n",
              " 'surrell': 53344,\n",
              " 'flowless': 52229,\n",
              " 'sheirk': 52230,\n",
              " \"'three\": 40923,\n",
              " \"peterson'\": 52231,\n",
              " 'ooverall': 52232,\n",
              " 'perchance': 40924,\n",
              " 'bottom': 1321,\n",
              " 'chabert': 53363,\n",
              " 'sneha': 52233,\n",
              " 'inhuman': 13888,\n",
              " 'ichii': 52234,\n",
              " 'ursla': 52235,\n",
              " 'completly': 30598,\n",
              " 'moviedom': 40925,\n",
              " 'raddick': 52236,\n",
              " 'brundage': 51995,\n",
              " 'brigades': 40926,\n",
              " 'starring': 1181,\n",
              " \"'goal'\": 52237,\n",
              " 'caskets': 52238,\n",
              " 'willcock': 52239,\n",
              " \"threesome's\": 52240,\n",
              " \"mosque'\": 52241,\n",
              " \"cover's\": 52242,\n",
              " 'spaceships': 17637,\n",
              " 'anomalous': 40927,\n",
              " 'ptsd': 27655,\n",
              " 'shirdan': 52243,\n",
              " 'obscenity': 21962,\n",
              " 'lemmings': 30599,\n",
              " 'duccio': 30600,\n",
              " \"levene's\": 52244,\n",
              " \"'gorby'\": 52245,\n",
              " \"teenager's\": 25255,\n",
              " 'marshall': 5340,\n",
              " 'honeymoon': 9095,\n",
              " 'shoots': 3231,\n",
              " 'despised': 12258,\n",
              " 'okabasho': 52246,\n",
              " 'fabric': 8289,\n",
              " 'cannavale': 18515,\n",
              " 'raped': 3537,\n",
              " \"tutt's\": 52247,\n",
              " 'grasping': 17638,\n",
              " 'despises': 18516,\n",
              " \"thief's\": 40928,\n",
              " 'rapes': 8926,\n",
              " 'raper': 52248,\n",
              " \"eyre'\": 27656,\n",
              " 'walchek': 52249,\n",
              " \"elmo's\": 23386,\n",
              " 'perfumes': 40929,\n",
              " 'spurting': 21918,\n",
              " \"exposition'\\x85\": 52250,\n",
              " 'denoting': 52251,\n",
              " 'thesaurus': 34740,\n",
              " \"shoot'\": 40930,\n",
              " 'bonejack': 49759,\n",
              " 'simpsonian': 52253,\n",
              " 'hebetude': 30601,\n",
              " \"hallow's\": 34741,\n",
              " 'desperation\\x85': 52254,\n",
              " 'incinerator': 34742,\n",
              " 'congratulations': 10308,\n",
              " 'humbled': 52255,\n",
              " \"else's\": 5924,\n",
              " 'trelkovski': 40845,\n",
              " \"rape'\": 52256,\n",
              " \"'chapters'\": 59386,\n",
              " '1600s': 52257,\n",
              " 'martian': 7253,\n",
              " 'nicest': 25256,\n",
              " 'eyred': 52259,\n",
              " 'passenger': 9457,\n",
              " 'disgrace': 6041,\n",
              " 'moderne': 52260,\n",
              " 'barrymore': 5120,\n",
              " 'yankovich': 52261,\n",
              " 'moderns': 40931,\n",
              " 'studliest': 52262,\n",
              " 'bedsheet': 52263,\n",
              " 'decapitation': 14900,\n",
              " 'slurring': 52264,\n",
              " \"'nunsploitation'\": 52265,\n",
              " \"'character'\": 34743,\n",
              " 'cambodia': 9880,\n",
              " 'rebelious': 52266,\n",
              " 'pasadena': 27657,\n",
              " 'crowne': 40932,\n",
              " \"'bedchamber\": 52267,\n",
              " 'conjectural': 52268,\n",
              " 'appologize': 52269,\n",
              " 'halfassing': 52270,\n",
              " 'paycheque': 57816,\n",
              " 'palms': 20606,\n",
              " \"'islands\": 52271,\n",
              " 'hawked': 40933,\n",
              " 'palme': 21919,\n",
              " 'conservatively': 40934,\n",
              " 'larp': 64007,\n",
              " 'palma': 5558,\n",
              " 'smelling': 21920,\n",
              " 'aragorn': 12998,\n",
              " 'hawker': 52272,\n",
              " 'hawkes': 52273,\n",
              " 'explosions': 3975,\n",
              " 'loren': 8059,\n",
              " \"pyle's\": 52274,\n",
              " 'shootout': 6704,\n",
              " \"mike's\": 18517,\n",
              " \"driscoll's\": 52275,\n",
              " 'cogsworth': 40935,\n",
              " \"britian's\": 52276,\n",
              " 'childs': 34744,\n",
              " \"portrait's\": 52277,\n",
              " 'chain': 3626,\n",
              " 'whoever': 2497,\n",
              " 'puttered': 52278,\n",
              " 'childe': 52279,\n",
              " 'maywether': 52280,\n",
              " 'chair': 3036,\n",
              " \"rance's\": 52281,\n",
              " 'machu': 34745,\n",
              " 'ballet': 4517,\n",
              " 'grapples': 34746,\n",
              " 'summerize': 76152,\n",
              " 'freelance': 30603,\n",
              " \"andrea's\": 52283,\n",
              " '\\x91very': 52284,\n",
              " 'coolidge': 45879,\n",
              " 'mache': 18518,\n",
              " 'balled': 52285,\n",
              " 'grappled': 40937,\n",
              " 'macha': 18519,\n",
              " 'underlining': 21921,\n",
              " 'macho': 5623,\n",
              " 'oversight': 19507,\n",
              " 'machi': 25257,\n",
              " 'verbally': 11311,\n",
              " 'tenacious': 21922,\n",
              " 'windshields': 40938,\n",
              " 'paychecks': 18557,\n",
              " 'jerk': 3396,\n",
              " \"good'\": 11931,\n",
              " 'prancer': 34748,\n",
              " 'prances': 21923,\n",
              " 'olympus': 52286,\n",
              " 'lark': 21924,\n",
              " 'embark': 10785,\n",
              " 'gloomy': 7365,\n",
              " 'jehaan': 52287,\n",
              " 'turaqui': 52288,\n",
              " \"child'\": 20607,\n",
              " 'locked': 2894,\n",
              " 'pranced': 52289,\n",
              " 'exact': 2588,\n",
              " 'unattuned': 52290,\n",
              " 'minute': 783,\n",
              " 'skewed': 16118,\n",
              " 'hodgins': 40940,\n",
              " 'skewer': 34749,\n",
              " 'think\\x85': 52291,\n",
              " 'rosenstein': 38765,\n",
              " 'helmit': 52292,\n",
              " 'wrestlemanias': 34750,\n",
              " 'hindered': 16826,\n",
              " \"martha's\": 30604,\n",
              " 'cheree': 52293,\n",
              " \"pluckin'\": 52294,\n",
              " 'ogles': 40941,\n",
              " 'heavyweight': 11932,\n",
              " 'aada': 82190,\n",
              " 'chopping': 11312,\n",
              " 'strongboy': 61534,\n",
              " 'hegemonic': 41342,\n",
              " 'adorns': 40942,\n",
              " 'xxth': 41346,\n",
              " 'nobuhiro': 34751,\n",
              " 'capitães': 52298,\n",
              " 'kavogianni': 52299,\n",
              " 'antwerp': 13422,\n",
              " 'celebrated': 6538,\n",
              " 'roarke': 52300,\n",
              " 'baggins': 40943,\n",
              " 'cheeseburgers': 31270,\n",
              " 'matras': 52301,\n",
              " \"nineties'\": 52302,\n",
              " \"'craig'\": 52303,\n",
              " 'celebrates': 12999,\n",
              " 'unintentionally': 3383,\n",
              " 'drafted': 14362,\n",
              " 'climby': 52304,\n",
              " '303': 52305,\n",
              " 'oldies': 18520,\n",
              " 'climbs': 9096,\n",
              " 'honour': 9655,\n",
              " 'plucking': 34752,\n",
              " '305': 30074,\n",
              " 'address': 5514,\n",
              " 'menjou': 40944,\n",
              " \"'freak'\": 42592,\n",
              " 'dwindling': 19508,\n",
              " 'benson': 9458,\n",
              " 'white’s': 52307,\n",
              " 'shamelessness': 40945,\n",
              " 'impacted': 21925,\n",
              " 'upatz': 52308,\n",
              " 'cusack': 3840,\n",
              " \"flavia's\": 37567,\n",
              " 'effette': 52309,\n",
              " 'influx': 34753,\n",
              " 'boooooooo': 52310,\n",
              " 'dimitrova': 52311,\n",
              " 'houseman': 13423,\n",
              " 'bigas': 25259,\n",
              " 'boylen': 52312,\n",
              " 'phillipenes': 52313,\n",
              " 'fakery': 40946,\n",
              " \"grandpa's\": 27658,\n",
              " 'darnell': 27659,\n",
              " 'undergone': 19509,\n",
              " 'handbags': 52315,\n",
              " 'perished': 21926,\n",
              " 'pooped': 37778,\n",
              " 'vigour': 27660,\n",
              " 'opposed': 3627,\n",
              " 'etude': 52316,\n",
              " \"caine's\": 11799,\n",
              " 'doozers': 52317,\n",
              " 'photojournals': 34754,\n",
              " 'perishes': 52318,\n",
              " 'constrains': 34755,\n",
              " 'migenes': 40948,\n",
              " 'consoled': 30605,\n",
              " 'alastair': 16827,\n",
              " 'wvs': 52319,\n",
              " 'ooooooh': 52320,\n",
              " 'approving': 34756,\n",
              " 'consoles': 40949,\n",
              " 'disparagement': 52064,\n",
              " 'futureistic': 52322,\n",
              " 'rebounding': 52323,\n",
              " \"'date\": 52324,\n",
              " 'gregoire': 52325,\n",
              " 'rutherford': 21927,\n",
              " 'americanised': 34757,\n",
              " 'novikov': 82196,\n",
              " 'following': 1042,\n",
              " 'munroe': 34758,\n",
              " \"morita'\": 52326,\n",
              " 'christenssen': 52327,\n",
              " 'oatmeal': 23106,\n",
              " 'fossey': 25260,\n",
              " 'livered': 40950,\n",
              " 'listens': 13000,\n",
              " \"'marci\": 76164,\n",
              " \"otis's\": 52330,\n",
              " 'thanking': 23387,\n",
              " 'maude': 16019,\n",
              " 'extensions': 34759,\n",
              " 'ameteurish': 52332,\n",
              " \"commender's\": 52333,\n",
              " 'agricultural': 27661,\n",
              " 'convincingly': 4518,\n",
              " 'fueled': 17639,\n",
              " 'mahattan': 54014,\n",
              " \"paris's\": 40952,\n",
              " 'vulkan': 52336,\n",
              " 'stapes': 52337,\n",
              " 'odysessy': 52338,\n",
              " 'harmon': 12259,\n",
              " 'surfing': 4252,\n",
              " 'halloran': 23494,\n",
              " 'unbelieveably': 49580,\n",
              " \"'offed'\": 52339,\n",
              " 'quadrant': 30607,\n",
              " 'inhabiting': 19510,\n",
              " 'nebbish': 34760,\n",
              " 'forebears': 40953,\n",
              " 'skirmish': 34761,\n",
              " 'ocassionally': 52340,\n",
              " \"'resist\": 52341,\n",
              " 'impactful': 21928,\n",
              " 'spicier': 52342,\n",
              " 'touristy': 40954,\n",
              " \"'football'\": 52343,\n",
              " 'webpage': 40955,\n",
              " 'exurbia': 52345,\n",
              " 'jucier': 52346,\n",
              " 'professors': 14901,\n",
              " 'structuring': 34762,\n",
              " 'jig': 30608,\n",
              " 'overlord': 40956,\n",
              " 'disconnect': 25261,\n",
              " 'sniffle': 82201,\n",
              " 'slimeball': 40957,\n",
              " 'jia': 40958,\n",
              " 'milked': 16828,\n",
              " 'banjoes': 40959,\n",
              " 'jim': 1237,\n",
              " 'workforces': 52348,\n",
              " 'jip': 52349,\n",
              " 'rotweiller': 52350,\n",
              " 'mundaneness': 34763,\n",
              " \"'ninja'\": 52351,\n",
              " \"dead'\": 11040,\n",
              " \"cipriani's\": 40960,\n",
              " 'modestly': 20608,\n",
              " \"professor'\": 52352,\n",
              " 'shacked': 40961,\n",
              " 'bashful': 34764,\n",
              " 'sorter': 23388,\n",
              " 'overpowering': 16120,\n",
              " 'workmanlike': 18521,\n",
              " 'henpecked': 27662,\n",
              " 'sorted': 18522,\n",
              " \"jōb's\": 52354,\n",
              " \"'always\": 52355,\n",
              " \"'baptists\": 34765,\n",
              " 'dreamcatchers': 52356,\n",
              " \"'silence'\": 52357,\n",
              " 'hickory': 21929,\n",
              " 'fun\\x97yet': 52358,\n",
              " 'breakumentary': 52359,\n",
              " 'didn': 15496,\n",
              " 'didi': 52360,\n",
              " 'pealing': 52361,\n",
              " 'dispite': 40962,\n",
              " \"italy's\": 25262,\n",
              " 'instability': 21930,\n",
              " 'quarter': 6539,\n",
              " 'quartet': 12608,\n",
              " 'padmé': 52362,\n",
              " \"'bleedmedry\": 52363,\n",
              " 'pahalniuk': 52364,\n",
              " 'honduras': 52365,\n",
              " 'bursting': 10786,\n",
              " \"pablo's\": 41465,\n",
              " 'irremediably': 52367,\n",
              " 'presages': 40963,\n",
              " 'bowlegged': 57832,\n",
              " 'dalip': 65183,\n",
              " 'entering': 6260,\n",
              " 'newsradio': 76172,\n",
              " 'presaged': 54150,\n",
              " \"giallo's\": 27663,\n",
              " 'bouyant': 40964,\n",
              " 'amerterish': 52368,\n",
              " 'rajni': 18523,\n",
              " 'leeves': 30610,\n",
              " 'macauley': 34767,\n",
              " 'seriously': 612,\n",
              " 'sugercoma': 52369,\n",
              " 'grimstead': 52370,\n",
              " \"'fairy'\": 52371,\n",
              " 'zenda': 30611,\n",
              " \"'twins'\": 52372,\n",
              " 'realisation': 17640,\n",
              " 'highsmith': 27664,\n",
              " 'raunchy': 7817,\n",
              " 'incentives': 40965,\n",
              " 'flatson': 52374,\n",
              " 'snooker': 35097,\n",
              " 'crazies': 16829,\n",
              " 'crazier': 14902,\n",
              " 'grandma': 7094,\n",
              " 'napunsaktha': 52375,\n",
              " 'workmanship': 30612,\n",
              " 'reisner': 52376,\n",
              " \"sanford's\": 61306,\n",
              " '\\x91doña': 52377,\n",
              " 'modest': 6108,\n",
              " \"everything's\": 19153,\n",
              " 'hamer': 40966,\n",
              " \"couldn't'\": 52379,\n",
              " 'quibble': 13001,\n",
              " 'socking': 52380,\n",
              " 'tingler': 21931,\n",
              " 'gutman': 52381,\n",
              " 'lachlan': 40967,\n",
              " 'tableaus': 52382,\n",
              " 'headbanger': 52383,\n",
              " 'spoken': 2847,\n",
              " 'cerebrally': 34768,\n",
              " \"'road\": 23490,\n",
              " 'tableaux': 21932,\n",
              " \"proust's\": 40968,\n",
              " 'periodical': 40969,\n",
              " \"shoveller's\": 52385,\n",
              " 'tamara': 25263,\n",
              " 'affords': 17641,\n",
              " 'concert': 3249,\n",
              " \"yara's\": 87955,\n",
              " 'someome': 52386,\n",
              " 'lingering': 8424,\n",
              " \"abraham's\": 41511,\n",
              " 'beesley': 34769,\n",
              " 'cherbourg': 34770,\n",
              " 'kagan': 28624,\n",
              " 'snatch': 9097,\n",
              " \"miyazaki's\": 9260,\n",
              " 'absorbs': 25264,\n",
              " \"koltai's\": 40970,\n",
              " 'tingled': 64027,\n",
              " 'crossroads': 19511,\n",
              " 'rehab': 16121,\n",
              " 'falworth': 52389,\n",
              " 'sequals': 52390,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "scymR57QncbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cambiar la posición del diccionario Key Value\n",
        "reversed_word_index = dict((value, key) for (key, value) in word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIiu2bDencbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_text_from_vector(v):\n",
        "    return ' '.join(reversed_word_index.get(i-3, '?') for i in v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62zZyk77ncbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b808dc00-a374-48cc-dbb3-4451c8027b1a"
      },
      "cell_type": "code",
      "source": [
        "get_text_from_vector(x_train[4][0:10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? worst mistake of my life br br i picked'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "AweE7naPqEO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2d0e615-61f0-46b6-a4a5-d6d0dc59bff3"
      },
      "cell_type": "code",
      "source": [
        "# 0 es review negativa\n",
        "y_train[4]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "4a5E2NGbqRm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "e1aebeb7-8a91-4975-e75b-f0a4a669519a"
      },
      "cell_type": "code",
      "source": [
        "plt.hist([len(x) for x in x_train], bins=50)\n",
        "plt.xlim([0,1000])\n",
        "plt.xlabel('Word Counter');"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAG6CAYAAAB6GOwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 748.8x514.8 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cqFP35RMncbp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare data for the network\n",
        "\n",
        "We need to prepare the data to be an input to the neural network. The input must be a **tensor**. In our case, all vectors should be of the same length. But not all reviews are of the same size, so the vectors will have different sizes. How can we overcome this problem?\n",
        "\n",
        "* We can zero-pad the vectors, so all of them have the same size, and then combine them in a tensor. We would need to add an *Embedding* layer to learn **word embeddings** (more later)\n",
        "* Or we can use 1-HOT encoding\n",
        "\n",
        "In both cases, we will have vectors of size $10^4$ (the maximum number of words). Let's go with the 1-HOT encoding."
      ]
    },
    {
      "metadata": {
        "id": "HOOP3Ev3ncbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hC6654PvXbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "409f9f9a-bb0e-45e9-ea21-56bb62d6b50f"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_train.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "nKmlXwWuwOF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "513ed969-753e-4a30-cc74-ed4736f2ad22"
      },
      "cell_type": "code",
      "source": [
        "x_train[0:5,0:7]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., 0., 1., 1., 1.],\n",
              "       [0., 1., 1., 0., 1., 1., 1.],\n",
              "       [0., 1., 1., 0., 1., 0., 1.],\n",
              "       [0., 1., 1., 0., 1., 1., 1.],\n",
              "       [0., 1., 1., 0., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "gnCn4h7_wXN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLXZgkQgncb0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE 1**. Can you see any problem with this approach? How would you solve it?\n",
        "\n",
        "**EXERCISE 2**. Do we need to transform the labels? Why? Or why not?"
      ]
    },
    {
      "metadata": {
        "id": "RGROYwBKncb3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's build the model"
      ]
    },
    {
      "metadata": {
        "id": "m54kBv0vDkNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.activations import softmax, elu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64qhwUbGOdtd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  m = Sequential()\n",
        "  m.add(Dense(units=128, activation=elu,input_shape=(10000,)))\n",
        "  m.add(Dense(units=64, activation=elu))\n",
        "  m.add(Dense(units=16, activation=elu))\n",
        "  m.add(Dense(units=1, activation='sigmoid'))\n",
        "  m.summary()\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oVNDnZpmxCG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "19cca556-96c5-4b30-ca32-4e443c52a31d"
      },
      "cell_type": "code",
      "source": [
        "m = build_model()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               1280128   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,289,441\n",
            "Trainable params: 1,289,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1lsEYLYYxJ7X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m.compile(\n",
        "          optimizer=optimizer.rmsprop(),\n",
        "          \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fKvj5iEHnccC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analyze performance"
      ]
    },
    {
      "metadata": {
        "id": "0nNXBbdgnccH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1x2_SWG8nccZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We cannot find a satisfactory model with what we have learned so far. Is there any way to have a better representation of text that can provide better results?"
      ]
    },
    {
      "metadata": {
        "id": "ouanf9fUnccb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WxDJ8XDnccj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word embeddings\n",
        "\n",
        "Using 1-HOT encoded vectors produce large and sparse tensors, that are difficult to learn from using a neural network. Word embeddings are compact vectors, representing words in a vector space. These vectors are learnt in a neural network, with a layer of type *Embedding*. We can also even use pre-trained word embeddings, to improve our model\n",
        "\n",
        "![](./imgs/07_embeddings.png)\n",
        "\n",
        "To generate  an embedding, we need to tokenize the text, transforming words into indices, and then we use these lists of numbers to produce the vectorial representation:\n",
        "\n",
        "![](./imgs/08_embeddings.png)\n",
        "\n",
        "More info:\n",
        "* http://www.offconvex.org/2015/12/12/word-embeddings-1/\n",
        "* http://www.offconvex.org/2016/02/14/word-embeddings-2/"
      ]
    },
    {
      "metadata": {
        "id": "h_coMKqcnccp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Input data for word embeddings"
      ]
    },
    {
      "metadata": {
        "id": "7vRNOghAncct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eOIDhvYBnccx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's build the model with embeddings"
      ]
    },
    {
      "metadata": {
        "id": "yUEARK7Lncc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GjHbo7-ncdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyze performance"
      ]
    },
    {
      "metadata": {
        "id": "WpngjCCyncdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not bad, with just an embedding layer, we get $75\\%$ accuracy"
      ]
    },
    {
      "metadata": {
        "id": "ts0YX7AwncdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8EzfqSxncdW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How many reviews will be misclassified?"
      ]
    },
    {
      "metadata": {
        "id": "QbzgdyLGncdX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R7bce4OZncde",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check some of the predictions"
      ]
    },
    {
      "metadata": {
        "id": "KY5-s2Ojncdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = 123\n",
        "# N = 2344"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZAhk0csncd5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwiyhO6RnceC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So this prediction is correct. It says the review is negative. Let's have a look at the text:"
      ]
    },
    {
      "metadata": {
        "id": "lKDxKL6inceD",
        "colab_type": "code",
        "colab": {},
        "outputId": "2ff3bd9b-fe92-4d06-cf41-258cde815325"
      },
      "cell_type": "code",
      "source": [
        "get_text_from_vector(test_text[N])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? if you believe that any given war movie can make you really feel the war you need to see called the ? are flying in english it tells the story of ? ? and boris who are in love on the verge of wwii they are walking along the ? watching the ? fly by when the war starts boris is promptly sent off to war ? hides out with a family and ends up marrying the son whom she does not love boris meanwhile continues ? through the countryside fighting the nazis and experiencing all the horrors of war until he he runs out of energy when ? working in a military hospital receives this news she refuses to accept it until ? body arrives home on one of the trains simultaneously the radio ? that germany has ? and the allied powers have won the war the soviet union lost 27 million citizens but it's the start of a new era br br this movie did a very good job showing the human impact of the war not only in the battlefield but also how it affected the ? population this is definitely a movie that everyone should see\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "X8SqdzpSnceN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Can we find all the reviews that are wrongly classified?"
      ]
    },
    {
      "metadata": {
        "id": "i1pNk60cnceP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z9KkpNZmnceS",
        "colab_type": "code",
        "colab": {},
        "outputId": "4cd88568-3241-47fa-dc37-942f2e57f87c"
      },
      "cell_type": "code",
      "source": [
        "get_text_from_vector(test_text[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely idiotic the things that happen with the dead kids are very cool but the alive people are absolute idiots i am a grown man pretty big and i can defend myself well however i would not do half the stuff the little girl does in this movie also the mother in this movie is reckless with her children to the point of neglect i wish i wasn't so angry about her and her actions because i would have otherwise enjoyed the flick what a number she was take my advise and fast forward through everything you see her do until the end also is anyone else getting sick of watching movies that are filmed so dark anymore one can hardly see what is being filmed as an audience we are ? involved with the actions on the screen so then why the hell can't we have night vision\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "HaqDuuZFnceW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Is the classifier symmetric?"
      ]
    },
    {
      "metadata": {
        "id": "H0LVVi3EnceY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aP3XCuIinceb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE** Can you construct the confusion matrix for this model? Can you calculate the precision and recall? How does it compare to accuracy?\n",
        "* See https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
        "\n",
        "**EXERCISE (more complex)** Keras decided some time ago to remove precision, recall and F1-score from the list of available metrics. Was it a good decision? Why? Why did the Keras' authors did not remove accuracy too?\n",
        "* https://github.com/keras-team/keras/issues/5794\n",
        "* https://github.com/keras-team/keras/issues/4592\n",
        "\n",
        "**EXERCISE** What is the ROC curve? Could you build the ROC curve for this model? How would you use a ROC curve to evaluate a classifier?\n",
        "* https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
        "* Help: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python"
      ]
    },
    {
      "metadata": {
        "id": "5f2BEJfWnced",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDvB3GUnnceg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's analyze wrong positives and wrong negatives separately. Then we will try to find a relationship between the words and the misclassification, both for false positives and negatives."
      ]
    },
    {
      "metadata": {
        "id": "iT7hftPVncei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wqOAkexncek",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's compare with the words of the true positives"
      ]
    },
    {
      "metadata": {
        "id": "cPUlyrMnncel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "easIWSGrnces",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So the most common words are very similar. Not surprising. Let's calculate the relative frequency of each word, and then find what are the words with the highest difference in relative frequency."
      ]
    },
    {
      "metadata": {
        "id": "vzgtgHr9ncev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09RKi-vSnce2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see words such as *great*, *best*, *excellent*, which have a large difference between the true and the false positives. So false positives seem to lack some extreme words, and the classifier is having a hard time trying to assign a category to those reviews."
      ]
    },
    {
      "metadata": {
        "id": "YvSISyFnnce7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}